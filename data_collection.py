# -*- coding: utf-8 -*-
"""csv and feature store-datacollection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c9AuG23R9kVCS0AJ0dWm4ScAiSzUPfu_
"""

import openmeteo_requests

import pandas as pd
import requests_cache
from retry_requests import retry
import os
from datetime import datetime, timedelta
import logging
from hopsworks import login
from hsfs.feature import Feature
from hsfs.feature_group import FeatureGroup

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
logger = logging.getLogger("DailyFeaturePipeline")

# --- Environment Variables ---
HOPSWORKS_API_KEY = os.getenv("HOPSWORKS_API_KEY")
HOPSWORKS_PROJECT = os.getenv("HOPSWORKS_PROJECT")
assert HOPSWORKS_API_KEY, "HOPSWORKS_API_KEY must be set."
assert HOPSWORKS_PROJECT, "HOPSWORKS_PROJECT must be set."

FEATURE_GROUP_NAME = "karachi_raw_data_store"
FEATURE_GROUP_VERSION = 1
PRIMARY_KEY = ["date_str"]
RAW_DATA_PATH = "Resources/karachi_merged_data_aqi.csv"

# --- Hopsworks Connection ---
logger.info("Connecting to Hopsworks...")
project = hopsworks.login(project=HOPSWORKS_PROJECT, api_key_value=HOPSWORKS_API_KEY)
fs = project.get_feature_store()
dataset_api = project.get_dataset_api()

# Setup the Open-Meteo API client with cache and retry on error
cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)
retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)
openmeteo = openmeteo_requests.Client(session = retry_session)

RUN_LOG = "data_collection_last_run.log"

def already_ran_today():
    if os.path.exists(RUN_LOG):
        with open(RUN_LOG, "r") as f:
            last_run = f.read().strip()
            if last_run == datetime.now().strftime("%Y-%m-%d"):
                logger.info("Script already ran today.")
                return True
    return False

def update_run_log():
    with open(RUN_LOG, "w") as f:
        f.write(datetime.now().strftime("%Y-%m-%d"))

if already_ran_today():
    exit(0)

update_run_log()

# Calculate yesterday's date
YESTERDAY = (datetime.utcnow() - timedelta(days=1)).date()
YESTERDAY_STR = YESTERDAY.strftime('%Y-%m-%d')

# Make sure all required weather variables are listed here
# The order of variables in hourly or daily is important to assign them correctly below
url = "https://air-quality-api.open-meteo.com/v1/air-quality"
params = {
    "latitude": 24.8608,
    "longitude": 67.0104,
    "start_date": YESTERDAY_STR,
    "end_date": YESTERDAY_STR,
    "hourly": ["pm10", "pm2_5", "carbon_monoxide", "carbon_dioxide", "nitrogen_dioxide", "sulphur_dioxide", "ozone"],
    "current": ["pm10", "pm2_5", "carbon_monoxide", "nitrogen_dioxide", "sulphur_dioxide", "ozone"],
    "timezone": "UTC"
}
responses = openmeteo.weather_api(url, params=params)

# Process first location. Add a for-loop for multiple locations or weather models
response = responses[0]
print(f"Coordinates {response.Latitude()}°N {response.Longitude()}°E")
print(f"Elevation {response.Elevation()} m asl")
print(f"Timezone {response.Timezone()}{response.TimezoneAbbreviation()}")
print(f"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s")

# Current values. The order of variables needs to be the same as requested.
current = response.Current()
current_pm10 = current.Variables(0).Value()
current_pm2_5 = current.Variables(1).Value()
current_carbon_monoxide = current.Variables(2).Value()
current_nitrogen_dioxide = current.Variables(3).Value()
current_sulphur_dioxide = current.Variables(4).Value()
current_ozone = current.Variables(5).Value()

print(f"Current time {current.Time()}")
print(f"Current pm10 {current_pm10}")
print(f"Current pm2_5 {current_pm2_5}")
print(f"Current carbon_monoxide {current_carbon_monoxide}")
print(f"Current nitrogen_dioxide {current_nitrogen_dioxide}")
print(f"Current sulphur_dioxide {current_sulphur_dioxide}")
print(f"Current ozone {current_ozone}")

# Process hourly data. The order of variables needs to be the same as requested.
hourly = response.Hourly()
hourly_pm10 = hourly.Variables(0).ValuesAsNumpy()
hourly_pm2_5 = hourly.Variables(1).ValuesAsNumpy()
hourly_carbon_monoxide = hourly.Variables(2).ValuesAsNumpy()
hourly_carbon_dioxide = hourly.Variables(3).ValuesAsNumpy()
hourly_nitrogen_dioxide = hourly.Variables(4).ValuesAsNumpy()
hourly_sulphur_dioxide = hourly.Variables(5).ValuesAsNumpy()
hourly_ozone = hourly.Variables(6).ValuesAsNumpy()

hourly_data = {"date": pd.date_range(
        start = pd.to_datetime(hourly.Time(), unit = "s", utc = True),
        end = pd.to_datetime(hourly.TimeEnd(), unit = "s", utc = True),
        freq = pd.Timedelta(seconds = hourly.Interval()),
        inclusive = "left"
)}

hourly_data["pm10"] = hourly_pm10
hourly_data["pm2_5"] = hourly_pm2_5
hourly_data["carbon_monoxide"] = hourly_carbon_monoxide
hourly_data["carbon_dioxide"] = hourly_carbon_dioxide
hourly_data["nitrogen_dioxide"] = hourly_nitrogen_dioxide
hourly_data["sulphur_dioxide"] = hourly_sulphur_dioxide
hourly_data["ozone"] = hourly_ozone

air_quality_dataframe = pd.DataFrame(data = hourly_data)
print(air_quality_dataframe)

# Define the conversion factors from µg/m³ to ppb for each gas
conversion_factors = {
    'carbon_monoxide': {'factor_ppb': 28.01 / 24.45, 'target_unit_ppb': 'ppb'},
    'nitrogen_dioxide': {'factor_ppb': 46.01 / 24.45, 'target_unit_ppb': 'ppb'},
    'sulphur_dioxide': {'factor_ppb': 64.07 / 24.45, 'target_unit_ppb': 'ppb'},
    'ozone': {'factor_ppb': 48.00 / 24.45, 'target_unit_ppb': 'ppb'},
    'carbon_dioxide': {'factor_ppb': 44.01 / 24.45, 'target_unit_ppb': 'ppb'}
}

# Convert units and create new columns
# PM2.5 and PM10 are in μg/m³. Calculate 24-hour rolling averages.
air_quality_dataframe['PM2.5 (μg/m³) 24h'] = air_quality_dataframe['pm2_5'].rolling(window=24, min_periods=1).mean()
air_quality_dataframe['PM10 (μg/m³) 24h'] = air_quality_dataframe['pm10'].rolling(window=24, min_periods=1).mean()


# Convert gases to ppb and calculate rolling averages where required for AQI
if 'carbon_monoxide' in air_quality_dataframe.columns:
    # Convert µg/m³ to ppb
    air_quality_dataframe['Carbon Monoxide (ppb) Hourly'] = air_quality_dataframe['carbon_monoxide'] / conversion_factors['carbon_monoxide']['factor_ppb']
    # Convert CO ppb to ppm (1 ppm = 1000 ppb) and calculate 8-hour rolling average
    air_quality_dataframe['CO (ppm) 8h'] = (air_quality_dataframe['Carbon Monoxide (ppb) Hourly'] / 1000).rolling(window=8, min_periods=1).mean()

if 'nitrogen_dioxide' in air_quality_dataframe.columns:
    # Convert µg/m³ to ppb and store as 1h average
    air_quality_dataframe['NO2 (ppb) 1h'] = air_quality_dataframe['nitrogen_dioxide'] / conversion_factors['nitrogen_dioxide']['factor_ppb']


if 'sulphur_dioxide' in air_quality_dataframe.columns:
    # Convert µg/m³ to ppb
    air_quality_dataframe['Sulphur Dioxide (ppb) Hourly'] = air_quality_dataframe['sulphur_dioxide'] / conversion_factors['sulphur_dioxide']['factor_ppb']
    # Store as 1h average. EPA AQI for SO2 is based on 1-hour.
    air_quality_dataframe['SO2 (ppb) 1h'] = air_quality_dataframe['Sulphur Dioxide (ppb) Hourly']
    # Calculate 24-hour rolling average for SO2 as per requested column name, though 1h is used for AQI
    air_quality_dataframe['SO2 (ppb) 24h'] = air_quality_dataframe['Sulphur Dioxide (ppb) Hourly'].rolling(window=24, min_periods=1).mean()


if 'ozone' in air_quality_dataframe.columns:
    # Convert µg/m³ to ppb
    air_quality_dataframe['Ozone (ppb) Hourly'] = air_quality_dataframe['ozone'] / conversion_factors['ozone']['factor_ppb']
    # Store as 1h average
    air_quality_dataframe['O3 (ppb) 1h'] = air_quality_dataframe['Ozone (ppb) Hourly']
    # Calculate 8-hour rolling average
    air_quality_dataframe['O3 (ppb) 8h'] = air_quality_dataframe['Ozone (ppb) Hourly'].rolling(window=8, min_periods=1).mean()

if 'carbon_dioxide' in air_quality_dataframe.columns:
    # Convert µg/m³ to ppb (CO2 is not used for standard EPA AQI, but converting for completeness)
    air_quality_dataframe['Carbon Dioxide (ppb) Hourly'] = air_quality_dataframe['carbon_dioxide'] / conversion_factors['carbon_dioxide']['factor_ppb']


# Display the updated dataframe with new columns
display(air_quality_dataframe.head())

import numpy as np
import pandas as pd

def calculate_epa_aqi(pollutant, concentration, unit):
    """
    Calculates the US EPA Air Quality Index (AQI) for a given pollutant concentration.

    Args:
        pollutant (str): The name of the pollutant (e.g., 'PM2.5', 'PM10', 'CO', 'SO2', 'O3', 'NO2').
        concentration (float or np.ndarray or pd.Series): The pollutant concentration.
        unit (str): The unit of the concentration ('ug/m3' or 'ppb' or 'ppm').

    Returns:
        float or np.ndarray: The calculated AQI value(s). Returns NaN if pollutant or unit is invalid.
    """

    # EPA AQI Breakpoints and corresponding AQI values
    # Source: https://www.airnow.gov/sites/default/files/2020-05/aqi-calculator-download_0.xlsx
    # Note: This is a simplified version and might not cover all averaging periods or nuances
    # of the official EPA calculator.
    aqi_breakpoints = {
        'PM2.5': [(0.0, 12.0, 0, 50), (12.1, 35.4, 51, 100), (35.5, 55.4, 101, 150), (55.5, 150.4, 151, 200), (150.5, 250.4, 201, 300), (250.5, 350.4, 301, 400), (350.5, 500.4, 401, 500)], # 24-hour average
        'PM10': [(0, 54, 0, 50), (55, 154, 51, 100), (155, 254, 101, 150), (255, 354, 151, 200), (355, 424, 201, 300), (425, 504, 301, 400), (505, 604, 401, 500)], # 24-hour average
        'CO': [(0.0, 4.4, 0, 50), (4.5, 9.4, 51, 100), (9.5, 12.4, 101, 150), (12.5, 15.4, 151, 200), (15.5, 30.4, 201, 300), (30.5, 40.4, 301, 400), (40.5, 50.4, 401, 500)], # 8-hour average in ppm
        'SO2': [(0.0, 35, 0, 50), (36, 75, 51, 100), (76, 185, 101, 150), (186, 304, 151, 200), (305, 604, 201, 300), (605, 804, 301, 400), (805, 1004, 401, 500)], # 1-hour average in ppb
        'O3': [(0.0, 54, 0, 50), (55, 70, 51, 100), (71, 85, 101, 150), (86, 105, 151, 200), (106, 200, 201, 300)], # 8-hour average in ppb
        'NO2': [(0, 53, 0, 50), (54, 100, 51, 100), (101, 360, 101, 150), (361, 649, 151, 200), (650, 1249, 201, 300), (1250, 1649, 301, 400), (1650, 2049, 401, 500)] # 1-hour average in ppb
    }

    if pollutant not in aqi_breakpoints:
        print(f"Warning: No AQI breakpoints found for pollutant: {pollutant}")
        return np.nan

    breakpoints = aqi_breakpoints[pollutant]

    # Convert concentration to the required unit for AQI calculation if necessary
    # The current conversion factors are from ug/m3 to ppb.
    # We need to ensure the concentration is in the unit expected by the breakpoints.
    # Based on the breakpoints, O3, SO2, and NO2 breakpoints are in ppb, CO in ppm, PM2.5 and PM10 in ug/m3.

    if pollutant in ['O3', 'SO2', 'NO2'] and unit.lower() != 'ppb':
         print(f"Warning: {pollutant} AQI calculation requires ppb, but got {unit}")
         return np.nan
    elif pollutant == 'CO' and unit.lower() != 'ppm':
         print(f"Warning: {pollutant} AQI calculation requires ppm, but got {unit}")
         return np.nan
    elif pollutant in ['PM2.5', 'PM10'] and unit.lower() != 'ug/m3':
         print(f"Warning: {pollutant} AQI calculation requires ug/m3, but got {unit}")
         return np.nan

    # Convert pandas Series to numpy array for consistent processing
    if isinstance(concentration, pd.Series):
        concentration = concentration.values

    aqi_values = []
    if isinstance(concentration, np.ndarray):
        for c in concentration:
            aqi = np.nan
            for c_low, c_high, i_low, i_high in breakpoints:
                if c_low <= c and c <= c_high: # Modified comparison
                    aqi = ((i_high - i_low) / (c_high - c_low)) * (c - c_low) + i_low
                    break
            aqi_values.append(aqi)
        return np.array(aqi_values)
    else:
        aqi = np.nan
        for c_low, c_high, i_low, i_high in breakpoints:
            if c_low <= concentration and concentration <= c_high: # Modified comparison
                aqi = ((i_high - i_low) / (c_high - c_low)) * (concentration - c_low) + i_low
                break
        return aqi

# Print column names to debug KeyError
print(air_quality_dataframe.columns)

air_quality_dataframe['Calculated AQI PM2.5'] = calculate_epa_aqi('PM2.5', air_quality_dataframe['PM2.5 (μg/m³) 24h'], 'ug/m3')
air_quality_dataframe['Calculated AQI PM10'] = calculate_epa_aqi('PM10', air_quality_dataframe['PM10 (μg/m³) 24h'], 'ug/m3')
air_quality_dataframe['Calculated AQI CO'] = calculate_epa_aqi('CO', air_quality_dataframe['CO (ppm) 8h'], 'ppm')
air_quality_dataframe['Calculated AQI SO2'] = calculate_epa_aqi('SO2', air_quality_dataframe['SO2 (ppb) 1h'], 'ppb')
# For Ozone, use the 8-hour average breakpoints with the 1-hour data as per the column name provided
air_quality_dataframe['Calculated AQI O3'] = calculate_epa_aqi('O3', air_quality_dataframe['O3 (ppb) 8h'], 'ppb')
air_quality_dataframe['Calculated AQI NO2'] = calculate_epa_aqi('NO2', air_quality_dataframe['NO2 (ppb) 1h'], 'ppb')

# Calculate the overall calculated AQI as the maximum of the individual pollutant AQI values
pollutant_aqi_columns = ['Calculated AQI PM2.5', 'Calculated AQI PM10', 'Calculated AQI CO',
                         'Calculated AQI SO2', 'Calculated AQI O3', 'Calculated AQI NO2']
air_quality_dataframe[pollutant_aqi_columns] = air_quality_dataframe[pollutant_aqi_columns].astype(float) # Ensure the columns are numeric
air_quality_dataframe['Calculated Overall AQI'] = air_quality_dataframe[pollutant_aqi_columns].max(axis=1)

# Setup the Open-Meteo API client with cache and retry on error
cache_session = requests_cache.CachedSession('.cache', expire_after = -1)
retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)
openmeteo = openmeteo_requests.Client(session = retry_session)

# Define the URL for the historical weather archive API
url = "https://archive-api.open-meteo.com/v1/archive"

# Define the parameters for the API request
params = {
        "latitude": 24.8608,
        "longitude": 67.0104,
        "start_date": YESTERDAY_STR,
        "end_date": YESTERDAY_STR,
        "hourly": ["temperature_2m", "relative_humidity_2m", "rain", "wind_speed_10m", "wind_direction_10m", "wind_speed_100m", "wind_direction_100m"],
        "timezone": "UTC"
}

# Make the API request
responses = openmeteo.weather_api(url, params=params)

# Process first location. Add a for-loop for multiple locations or weather models
response = responses[0]
print(f"Coordinates {response.Latitude()}°N {response.Longitude()}°E")
print(f"Elevation {response.Elevation()} m asl")
print(f"Timezone {response.Timezone()}{response.TimezoneAbbreviation()}")
print(f"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s")

# Process hourly data. The order of variables needs to be the same as requested.
hourly = response.Hourly()
hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()
hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()
hourly_rain = hourly.Variables(2).ValuesAsNumpy()
hourly_wind_speed_10m = hourly.Variables(3).ValuesAsNumpy()
hourly_wind_direction_10m = hourly.Variables(4).ValuesAsNumpy()
hourly_wind_speed_100m = hourly.Variables(5).ValuesAsNumpy()
hourly_wind_direction_100m = hourly.Variables(6).ValuesAsNumpy()

# Create a dictionary hourly_data to store the date and the extracted hourly weather variables
hourly_data = {"date": pd.date_range(
        start = pd.to_datetime(hourly.Time(), unit = "s", utc = True),
        end = pd.to_datetime(hourly.TimeEnd(), unit = "s", utc = True),
        freq = pd.Timedelta(seconds = hourly.Interval()),
        inclusive = "left"
)}

hourly_data["temperature_2m"] = hourly_temperature_2m
hourly_data["relative_humidity_2m"] = hourly_relative_humidity_2m
hourly_data["rain"] = hourly_rain
hourly_data["wind_speed_10m"] = hourly_wind_speed_10m
hourly_data["wind_direction_10m"] = hourly_wind_direction_10m
hourly_data["wind_speed_100m"] = hourly_wind_speed_100m
hourly_data["wind_direction_100m"] = hourly_wind_direction_100m

# Create a pandas DataFrame named hourly_dataframe from the hourly_data dictionary
hourly_dataframe = pd.DataFrame(data = hourly_data)

# Print the first few rows of the hourly_dataframe
print(hourly_dataframe.head())

# Convert wind speed from m/s to km/h (1 m/s = 3.6 km/h)
hourly_dataframe['wind_speed_10m'] = hourly_dataframe['wind_speed_10m'] * 3.6
hourly_dataframe['wind_speed_100m'] = hourly_dataframe['wind_speed_100m'] * 3.6

# Display the updated dataframe
display(hourly_dataframe.head())

# Extract hour, day, and weekday from the 'date' column
hourly_dataframe['hour'] = hourly_dataframe['date'].dt.hour
hourly_dataframe['day'] = hourly_dataframe['date'].dt.day
hourly_dataframe['weekday'] = hourly_dataframe['date'].dt.weekday # Monday=0, Sunday=6

# Calculate the temperature change from the previous hour
hourly_dataframe['temperature_change_1h'] = hourly_dataframe['temperature_2m'].diff()

# Calculate the 24-hour rolling average of 'relative_humidity_2m'
hourly_dataframe['relative_humidity_2m_24h'] = hourly_dataframe['relative_humidity_2m'].rolling(window=24, min_periods=1).mean()

# Wind gust speed is not available in the current weather data, skipping this step.

# Display the updated dataframe with new features
display(hourly_dataframe.head())
display(hourly_dataframe.tail())

# Merge the two dataframes on the 'date' column
merged_dataframe = pd.merge(hourly_dataframe, air_quality_dataframe, on='date', how='inner')

# Display the head of the merged dataframe
display(merged_dataframe.head())

print(merged_dataframe.columns)

# Keep only the required columns
merged_dataframe = merged_dataframe[[
    'date',
    'temperature_2m',
    'relative_humidity_2m',
    'wind_speed_10m',
    'wind_direction_10m',
    'hour',
    'day',
    'weekday',
    'PM2.5 (μg/m³) 24h',
    'PM10 (μg/m³) 24h',
    'Carbon Monoxide (ppb) Hourly',
    'Sulphur Dioxide (ppb) Hourly',
    'Ozone (ppb) Hourly',
    'NO2 (ppb) 1h',
    'Calculated Overall AQI'
]]

# Rename columns
merged_dataframe.rename(columns={
    'temperature_2m': 'temperature',
    'relative_humidity_2m': 'humidity',
    'wind_speed_10m': 'wind_speed',
    'wind_direction_10m': 'wind_direction',
    'PM2.5 (μg/m³) 24h': 'PM2.5',
    'PM10 (μg/m³) 24h': 'PM10',
    'Carbon Monoxide (ppb) Hourly': 'CO',
    'Sulphur Dioxide (ppb) Hourly': 'SO2',
    'Ozone (ppb) Hourly': 'O3',
    'NO2 (ppb) 1h': 'NO2',
    'Calculated Overall AQI': 'AQI'
}, inplace=True)

# Print updated columns
print(merged_dataframe.columns)

# When saving, append to historical CSV
if os.path.exists('Resources/'):
    merged_dataframe.to_csv('karachi_merged_data_aqi.csv', mode='a', header=False, index=False)
else:
    merged_dataframe.to_csv('karachi_merged_data_aqi.csv', index=False)

df=pd.read_csv('karachi_merged_data_aqi.csv')

# import hopsworks

# def upload_to_hopsworks():
#     # Initialize Hopsworks connection
#     project = hopsworks.login()
#     dataset_api = project.get_dataset_api()

#     # Upload the file
#     dataset_api.upload(
#         local_path="karachi_merged_data_aqi.csv",
#         upload_path="Resources/karachi_merged_data_aqi.csv",
#         overwrite=True
#     )
#     print("Successfully uploaded aqi_data.csv to Hopsworks")

# if __name__ == "__main__":
#     upload_to_hopsworks()



import pandas as pd
import hopsworks
from hsfs.feature import Feature
from hsfs.feature_group import FeatureGroup
import os

# Step 1: Define final features
final_features = [
    'date', 'temperature', 'humidity', 'wind_speed', 'wind_direction',
    'hour', 'day', 'weekday', 'PM2.5', 'PM10',
    'CO', 'SO2', 'O3', 'NO2', 'AQI'
]
# Step 2: Select features
final_df = merged_dataframe[final_features].copy()

# Step 3: Add string version of timestamp for online primary key
final_df["date_str"] = pd.to_datetime(final_df["date"]).dt.strftime("%Y-%m-%d %H:%M:%S")

# Step 4: Lowercase all column names (required by Hopsworks)
final_df.columns = [col.lower() for col in final_df.columns]

# Rename columns with periods to underscores for Hopsworks compatibility
final_df.rename(columns={'pm2.5': 'pm2_5', 'pm10': 'pm10'}, inplace=True)

# Step 5: Upload raw feature set to Resources (optional)
# Download existing CSV if available
if os.path.exists("karachi_merged_data_aqi.csv"):
    old_df = pd.read_csv("karachi_merged_data_aqi.csv")
    combined_df = pd.concat([old_df, final_df]).drop_duplicates(subset=["date_str"])
else:
    combined_df = final_df.copy()
combined_df.to_csv("karachi_merged_data_aqi.csv", index=False)

# Step 6: Convert numeric columns to float64
numeric_cols = [
    'temperature', 'humidity', 'wind_speed', 'wind_direction',
    'hour', 'day', 'weekday', 'pm2_5', 'pm10',
    'co', 'so2', 'o3', 'no2', 'aqi'
]
combined_df[numeric_cols] = combined_df[numeric_cols].astype('float64')

# Step 7: Convert 'date' column to Python date objects
combined_df['date'] = pd.to_datetime(combined_df['date']).dt.date

# Step 8: Define schema
feature_group_schema = (
    [Feature(name=col, type="double") for col in combined_df.select_dtypes(include='number').columns if col != "date"] +
    [Feature(name="date", type="date")] +
    [Feature(name="date_str", type="string")]
)

# Step 9: Create or get feature group
feature_group_name = "karachi_raw_data_store"
feature_group_version = 1

try:
    fg = fs.get_feature_group(name=feature_group_name, version=feature_group_version)
    if fg is None:
        raise Exception("Feature group not found, will create.")
    print("Using existing feature group")
except Exception as e:
    print("Creating new feature group")
    fg = fs.create_feature_group(
        name=feature_group_name,
        version=feature_group_version,
        description="Final features for Karachi AQI model (online + offline)",
        primary_key=["date_str"],
        event_time="date",
        features=feature_group_schema,
        online_enabled=True
    )

# Read existing feature group data and append only new records
try:
    fg_hist = fg.read()
    fg_hist["date_str"] = fg_hist["date_str"].astype(str)
    new_records = combined_df[~combined_df["date_str"].isin(fg_hist["date_str"])]
    if not new_records.empty:
        fg.insert(new_records, write_options={"wait_for_job": True})
        print(f"Inserted {len(new_records)} new records into feature group.")
    else:
        print("No new records to insert into feature group.")
except Exception as e:
    print(f"Error reading/inserting feature group: {e}")

