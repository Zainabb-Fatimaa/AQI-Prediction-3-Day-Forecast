name: Daily Data Collection

on:
  schedule:
    - cron: '0 0 * * *'  # Runs at 00:00 UTC every day
  workflow_dispatch:

jobs:
  run_data_collection:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install hopsworks pandas

      - name: Set up environment variables
        run: |
          echo "HOPSWORKS_API_KEY=${{ secrets.HOPSWORKS_API_KEY }}" >> $GITHUB_ENV
          echo "HOPSWORKS_PROJECT=${{ secrets.HOPSWORKS_PROJECT }}" >> $GITHUB_ENV

      - name: Download karachi_merged_data_aqi.csv from Hopsworks
        run: |
          python -c "import hopsworks; project = hopsworks.login(); dataset_api = project.get_dataset_api(); dataset_api.download('Resources/karachi_merged_data_aqi.csv', 'karachi_merged_data_aqi.csv', overwrite=True)"

      - name: Download feature group from Hopsworks
        run: |
          python -c "import hopsworks, os; project = hopsworks.login(); fs = project.get_feature_store(); fg = fs.get_feature_group(name='karachi_raw_data_store', version=1); df = fg.read(); df.to_csv('feature_group_data.csv', index=False)"

      - name: Run data collection script
        run: python data_collection.py

      - name: Append new data to karachi_merged_data_aqi.csv
        run: |
          python -c "import pandas as pd; old = pd.read_csv('karachi_merged_data_aqi.csv'); new = pd.read_csv('karachi_merged_data_aqi.csv', skiprows=len(old)+1); merged = pd.concat([old, new]).drop_duplicates(subset=['date_str']); merged.to_csv('karachi_merged_data_aqi.csv', index=False)"

      - name: Append new data to feature group
        run: |
          python -c "import pandas as pd; fg_hist = pd.read_csv('feature_group_data.csv'); new = pd.read_csv('karachi_merged_data_aqi.csv'); merged_fg = pd.concat([fg_hist, new]).drop_duplicates(subset=['date_str']); merged_fg.to_csv('feature_group_data.csv', index=False)"

      - name: Upload updated karachi_merged_data_aqi.csv to Hopsworks
        run: |
          python -c "import hopsworks, os; project = hopsworks.login(); dataset_api = project.get_dataset_api(); dataset_api.upload('karachi_merged_data_aqi.csv', 'Resources', overwrite=True)"

      - name: Upload updated feature group to Hopsworks
        run: |
          python -c "import hopsworks, os, pandas as pd; project = hopsworks.login(); fs = project.get_feature_store(); fg = fs.get_feature_group(name='karachi_raw_data_store', version=1); merged_fg = pd.read_csv('feature_group_data.csv'); fg.insert(merged_fg, write_options={'wait_for_job': True})"
